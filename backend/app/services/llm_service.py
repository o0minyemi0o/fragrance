from google import genai
from app.config import settings
from app.prompts import get_accord_generation_prompt, get_formula_generation_prompt
import logging
import json

logger = logging.getLogger(__name__)

class LLMService:
    def __init__(self):
        try:
            logger.info("ğŸ”§ Gemini Client ì´ˆê¸°í™” ì¤‘...")
            self.client = genai.Client(api_key=settings.GOOGLE_API_KEY)
            logger.info("âœ“ Gemini Client ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"Gemini Client ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def generate_accord(self, accord_type: str) -> dict:
        """Accord ì¡°í•© ìƒì„±"""
        prompt = get_accord_generation_prompt(accord_type)

        try:
            logger.info(f"ğŸš€ Accord ìƒì„± ì‹œì‘: {accord_type}")
            response = self.client.models.generate_content(
                model="gemini-2.0-flash",
                contents=prompt
            )
            result_text = response.text
            logger.info(f"âœ“ Accord ì‘ë‹µ ì™„ë£Œ")
            
            # JSON íŒŒì‹±
            try:
                result = json.loads(result_text)
            except json.JSONDecodeError:
                # JSON ì¶”ì¶œ ì‹œë„
                start = result_text.find('{')
                end = result_text.rfind('}') + 1
                result = json.loads(result_text[start:end])
            
            return result
        except Exception as e:
            logger.error(f"Accord ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            raise

    def generate_formula(self, formula_type: str) -> dict:
        """Formula ì¡°í•© ìƒì„± (ì™„ì œí’ˆìš©, ê³ ì™„ì„±ë„)"""
        prompt = get_formula_generation_prompt(formula_type)

        try:
            logger.info(f"ğŸš€ Formula ìƒì„± ì‹œì‘: {formula_type}")
            response = self.client.models.generate_content(
                model="gemini-2.0-flash",
                contents=prompt
            )
            result_text = response.text
            logger.info(f"âœ“ Formula ì‘ë‹µ ì™„ë£Œ")
            
            try:
                result = json.loads(result_text)
            except json.JSONDecodeError:
                start = result_text.find('{')
                end = result_text.rfind('}') + 1
                result = json.loads(result_text[start:end])
            
            return result
        except Exception as e:
            logger.error(f"Formula ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            raise

    async def stream_chat(self, messages: list, system_prompt: str):
        """ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° ìƒì„±"""
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì²« ë©”ì‹œì§€ì— í¬í•¨
        chat_history = []
        
        if messages:
            first_message = f"{system_prompt}\n\nì‚¬ìš©ì ìš”ì²­: {messages[0]['content']}"
            chat_history.append({
                "role": "user",
                "parts": [{"text": first_message}]
            })
            
            for msg in messages[1:]:
                role = "model" if msg['role'] == "assistant" else "user"
                chat_history.append({
                    "role": role,
                    "parts": [{"text": msg['content']}]
                })
        
        response = self.client.models.generate_content_stream(
            model="gemini-2.0-flash-exp",
            contents=chat_history
        )
        
        for chunk in response:
            if chunk.text:
                yield chunk.text

llm_service = LLMService()